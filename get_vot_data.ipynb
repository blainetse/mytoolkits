{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "参考链接：https://zhuanlan.zhihu.com/p/369531344\n",
        "\n",
        "文件操作：https://blog.csdn.net/Baozijiaruqing/article/details/103900387"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "关于 `VOT` 数据集下载，直接看官方源码：https://github.com/votchallenge/toolkit\n",
        "\n",
        "下载链接：https://data.votchallenge.net/vot2019/longterm/description.json\n",
        "\n",
        "另外一种下载数据集的方法：https://blog.csdn.net/yiyayi1/article/details/103605762"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`VOT` 数据集格式：\n",
        "    vot[lt]year\n",
        "        - sequences\n",
        "            - airplane\n",
        "                - color\n",
        "                    - ....jpge\n",
        "                    - ...\n",
        "                - groundtruth.txt\n",
        "            - ...\n",
        "        - list.txt\n",
        "        - [description.json]\n",
        "        - [vot[lt]yesr.json]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install requests pandas\n",
        "# !pip install -U \"urllib3<1.25\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from urllib.parse import urlparse, urljoin\n",
        "\n",
        "\n",
        "def get_data(stack=\"vot-lt2022\"):\n",
        "    VOT_DATASETS = {\n",
        "        \"vot2013\": \"http://data.votchallenge.net/vot2013/dataset/description.json\",\n",
        "        \"vot2014\": \"http://data.votchallenge.net/vot2014/dataset/description.json\",\n",
        "        \"vot2015\": \"http://data.votchallenge.net/vot2015/dataset/description.json\",\n",
        "        \"vot-tir2015\": \"http://www.cvl.isy.liu.se/research/datasets/ltir/version1.0/ltir_v1_0_8bit.zip\",\n",
        "        \"vot2016\": \"http://data.votchallenge.net/vot2016/main/description.json\",\n",
        "        \"vot-tir2016\": \"http://data.votchallenge.net/vot2016/vot-tir2016.zip\",\n",
        "        \"vot2017\": \"http://data.votchallenge.net/vot2017/main/description.json\",\n",
        "        \"vot-st2018\": \"http://data.votchallenge.net/vot2018/main/description.json\",\n",
        "        \"vot-lt2018\": \"http://data.votchallenge.net/vot2018/longterm/description.json\",\n",
        "        \"vot-st2019\": \"http://data.votchallenge.net/vot2019/main/description.json\",\n",
        "        \"vot-lt2019\": \"http://data.votchallenge.net/vot2019/longterm/description.json\",\n",
        "        \"vot-rgbd2019\": \"http://data.votchallenge.net/vot2019/rgbd/description.json\",\n",
        "        \"vot-rgbt2019\": \"http://data.votchallenge.net/vot2019/rgbtir/meta/description.json\",\n",
        "        \"vot-st2020\": \"https://data.votchallenge.net/vot2020/shortterm/description.json\",\n",
        "        \"vot-rgbt2020\": \"http://data.votchallenge.net/vot2020/rgbtir/meta/description.json\",\n",
        "        \"vot-st2021\": \"https://data.votchallenge.net/vot2021/shortterm/description.json\",\n",
        "        \"vot-lt2022\": \"https://data.votchallenge.net/vot2022/lt/description.json\",\n",
        "        \"test\": \"http://data.votchallenge.net/toolkit/test.zip\",\n",
        "        \"segmentation\": \"http://box.vicos.si/tracking/vot20_test_dataset.zip\",\n",
        "    }\n",
        "    url = VOT_DATASETS[stack]\n",
        "    base_url = url.rsplit(\"/\", 1)[0] + \"/\"\n",
        "\n",
        "    try:\n",
        "        meta = requests.get(url).json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        raise Exception(\"Unable to read JSON file {}\".format(e))\n",
        "\n",
        "    global frames_url, annos_url, fnames\n",
        "    frames_url, annos_url, fnames = [], [], []\n",
        "    for sequence in meta[\"sequences\"]:\n",
        "        # get data name\n",
        "        fnames.append(sequence[\"name\"])\n",
        "\n",
        "        # get groundtruth zip file\n",
        "        url = sequence[\"annotations\"][\"url\"]\n",
        "        if bool(urlparse(url).netloc):\n",
        "            anno_url = url\n",
        "        else:\n",
        "            anno_url = urljoin(base_url, url)\n",
        "\n",
        "        # get pic zip file\n",
        "        url = sequence[\"channels\"][\"color\"][\"url\"]\n",
        "        if bool(urlparse(url).netloc):\n",
        "            frame_url = url\n",
        "        else:\n",
        "            frame_url = urljoin(base_url, url)\n",
        "\n",
        "        frames_url.append(frame_url)\n",
        "        annos_url.append(anno_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stack = \"vot-lt2019\"  ## 这里指定下载的数据集类型\n",
        "get_data(stack)\n",
        "\n",
        "for fname, url in zip(fnames, frames_url):\n",
        "        print(f\"{fname}: {url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 将数据写入 csv 文件\n",
        "import csv\n",
        "import os\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# 方法一：使用 csv 自带的接口，适合每行长度不一定全相等的情况\n",
        "def write2csv1(csvfile, fnames, urls):\n",
        "    if os.path.exists(csvfile):\n",
        "        print(f\"deleting {csvfile}...\")\n",
        "        os.remove(csvfile)\n",
        "\n",
        "    with open(csvfile, \"a+\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        # 1.写入 columns names\n",
        "        writer.writerow([\"filename\", \"urls\", \"state\"])\n",
        "        \n",
        "        for fname, url in zip(fnames, urls):\n",
        "            # 2.一行一行写入文件\n",
        "            # print(f\"正在将{fname}: {url} 写入到{csvfile}...\\n\")\n",
        "            writer.writerow([fname, url, \"False\"])\n",
        "\n",
        "# 方法二：使用 pandas\n",
        "def write2csv2(csvfile, fnames, urls):\n",
        "    if os.path.exists(csvfile):\n",
        "        print(f\"deleting {csvfile}...\")\n",
        "        os.remove(csvfile)\n",
        "    \n",
        "    # 1.创建一个 DataFrame 作为一行写入，以键值对——字典的形式存储\n",
        "    df = pd.DataFrame({\"filename\": fnames, \"urls\": urls, \"state\": [False]*50})\n",
        "    # 2.将 DataFrame 存储为 csv 文件，index 表示是否显示行名称（可以是数字，也可以是自定义的字符串）default=True\n",
        "    df.to_csv(csvfile, index=fnames, sep=\",\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = re.sub(\"[^0-9]\", \"\", stack)\n",
        "csvfile = {\n",
        "    \"frames\": \"votlt\" + version + \"_frames.csv\",\n",
        "    \"annos\": \"votlt\" + version + \"_annos.csv\",\n",
        "}\n",
        "\n",
        "def run_writer():\n",
        "    write2csv1(csvfile[\"frames\"], fnames, frames_url)\n",
        "    write2csv1(csvfile[\"annos\"], fnames, annos_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_writer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import requests, os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 屏蔽warning信息\n",
        "requests.packages.urllib3.disable_warnings()\n",
        "# 构建自己的代理 IP 池\n",
        "proxies = {\n",
        "    # 这里修改为自己的代理端口号，可在代理软件中进行查看更改，clash 默认是7890\n",
        "    \"http\": \"http://127.0.0.1:7890\",\n",
        "    \"https\": \"http://127.0.0.1:7890\",\n",
        "}\n",
        "# response = requests.get(url, proxies=proxies)\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.75 Safari/537.36\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 初级版：最原始的下载方法\n",
        "def download_v0(url, folder_path, fname, use_proxy=True):\n",
        "    \"\"\"\n",
        "    @description: download video frames and annotations\n",
        "    ---------\n",
        "    @param: - fname: [color][groundtruth]\n",
        "                - color: the frame of video\n",
        "                - groundtruth: the text annotation of bounding box\n",
        "    -------\n",
        "    @Returns: None\n",
        "    -------\n",
        "    \"\"\"\n",
        "    fname = os.path.join(folder_path, f\"{fname}.zip\")\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)  # 创建存放每一个图片集的单独文件夹\n",
        "\n",
        "    # if not os.path.exists(fname):\n",
        "    if not os.path.isfile(fname):\n",
        "        response = requests.get(url, stream=True, proxies=proxies if use_proxy else \"\", headers=headers)\n",
        "        with open(fname, \"wb\") as code:\n",
        "            for chunk in response.iter_content(chunk_size=1024 * 32):  # 边下载边存硬盘\n",
        "                if chunk:\n",
        "                    code.write(chunk)\n",
        "            time.sleep(0.1)\n",
        "    else:\n",
        "        print(f\"{fname.title()} exists and have totaly been downloaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 进阶版：使用 tqdm 显示下载进度\n",
        "def download_v1(url, folder_path, fname, use_proxy=True):\n",
        "    \"\"\"\n",
        "    @description: download video frames and annotations\n",
        "    ---------\n",
        "    @param: - fname: [color][groundtruth]\n",
        "                - color: the frame of video\n",
        "                - groundtruth: the text annotation of bounding box\n",
        "    -------\n",
        "    @Returns: None\n",
        "    -------\n",
        "    \"\"\"\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)  # 创建存放每一个图片集的单独文件夹\n",
        "\n",
        "    fname = os.path.join(folder_path, f\"{fname}.zip\")\n",
        "\n",
        "    ############# 断点续传实现 ##################\n",
        "    # 第一次请求是为了得到文件总大小\n",
        "    response = requests.get(\n",
        "        url, stream=True, verify=False, proxies=proxies if use_proxy else \"\"\n",
        "    )\n",
        "    total_size = int(response.headers[\"Content-Length\"])\n",
        "\n",
        "    if os.path.isfile(fname):\n",
        "        temp_size = os.path.getsize(fname)  # 本地已经下载的文件大小\n",
        "        if temp_size == total_size:\n",
        "            print(\n",
        "                # 注意双引号中不能包括双引号！！！只能使用外面双引号，内部单引号\n",
        "                f\"{fname.split('/')[-2] + '.zip'} exists and have totaly been downloaded!\"\n",
        "            )\n",
        "            return\n",
        "    else:\n",
        "        temp_size = 0\n",
        "\n",
        "    # 显示一下下载了多少\n",
        "    print(\n",
        "        f\"{fname.split('/')[-2] + '.zip'} downloaded: {temp_size/(1024*1024):.2f}MB || Total size: {total_size/(1024*1024):.2f}MB || Remaining download rate {1 - temp_size/total_size:.2f}\"\n",
        "    )\n",
        "    # 核心部分，这个是请求下载时，从本地文件已经下载过的后面下载\n",
        "    # headers = {'Range': 'bytes=%d-' % temp_size}\n",
        "    headers = {\n",
        "        \"Range\": f\"bytes={temp_size}-{total_size}\",\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.75 Safari/537.36\",\n",
        "    }\n",
        "    # 重新请求网址，加入新的请求头的\n",
        "    response = requests.get(\n",
        "        url,\n",
        "        stream=True,\n",
        "        verify=False,\n",
        "        headers=headers,\n",
        "        proxies=proxies if use_proxy else \"\",\n",
        "    )\n",
        "    ############################################\n",
        "\n",
        "    with tqdm.wrapattr(\n",
        "        open(fname, \"ab\"),  # 以 ab 追加的形式写入！！！\n",
        "        \"write\",\n",
        "        miniters=1,\n",
        "        # desc=url.split(\"/\")[-1],\n",
        "        desc=fname.split(\"/\")[-2] + \".zip\",\n",
        "        total=int(response.headers.get(\"content-length\", 0)),\n",
        "    ) as fout:\n",
        "        for chunk in response.iter_content(chunk_size=4096):\n",
        "            if chunk:\n",
        "                temp_size += len(chunk)\n",
        "                fout.write(chunk)\n",
        "                fout.flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "改进3，参考：https://blog.csdn.net/yiyayi1/article/details/103605762\n",
        "\n",
        "使用 `wget` 进行下载。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "需要注意一点的就是代理池的设置，代理软件不同，端口号不同，根据个人实际情况进行修改！\n",
        "\n",
        "使用连接池可以使得下载更加稳定，并且断线的风险比较小，当然，本项目中使用了断点续传的技术，断线后也不会重新下载，只会下载未下载的部分。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "断点续传参考链接：\n",
        "- https://blog.csdn.net/qq_35203425/article/details/80987880\n",
        "- https://blog.csdn.net/thewindkee/article/details/80189434\n",
        "- https://huyi-aliang.blog.csdn.net/article/details/120926552?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_paycolumn_v3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_paycolumn_v3&utm_relevant_index=2 这篇比较准确"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "改进：边下载边解压，这里的意思是下载完成一个，解压缩一个。\n",
        "\n",
        "`download` 之后再进行的 `unzip` 操作，由于 `download` 时我们采用了断点续传的技术，所以会保证这是一个完整的压缩包。\n",
        "\n",
        "如果在解压缩之后进行删除，那么就需要进行判断，用一个字典等来保存是否解压，是否成功下载完成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "\n",
        "def unzip_filev0(zip_src: str, dst_dir: str):\n",
        "    try:\n",
        "        zip_file = zipfile.ZipFile(zip_src, \"r\")\n",
        "        print(f\"Start unzip {zip_src.split('/')[-2]}\")\n",
        "        for file in zip_file.namelist():\n",
        "            zip_file.extract(file, dst_dir)\n",
        "\n",
        "        zip_file.close()\n",
        "        print(f\"Done! {zip_src.split('/')[-2].upper()} has been unziped fully!\")\n",
        "        os.remove(zip_src)\n",
        "        return True\n",
        "    except:\n",
        "        print(\"This is not zip file!\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def unzip_filev1(zip_src: str, dst_dir: str):\n",
        "    try:\n",
        "        with zipfile.ZipFile(file=zip_src) as zip_file:\n",
        "            # Loop over each file\n",
        "            print(f\"Start unzip {zip_src.split('/')[-2]}\")\n",
        "            for file in zip_file.namelist():\n",
        "                # Extract each file to another directory\n",
        "                # If you want to extract to current working directory, don't specify path\n",
        "                zip_file.extract(member=file, path=dst_dir)\n",
        "                \n",
        "            print(f\"Done! {zip_src.split('/')[-2].upper()} has been unziped fully!\")\n",
        "            os.remove(zip_src)\n",
        "            return True\n",
        "    except:\n",
        "        print(\"This is not zip file!\")\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 有关 `Python` 传参的一些知识：https://blog.csdn.net/xylin1012/article/details/81236122\n",
        "- 解压 `zip` 文件：https://wanglinyong.github.io/2018/06/28/Python%E5%8E%8B%E7%BC%A9%E8%A7%A3%E5%8E%8Bzip%E6%96%87%E4%BB%B6/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "root = f\"./VOT{version}_LT/sequences\"\n",
        "frames = pd.read_csv(csvfile[\"frames\"], header=0, index_col=0, usecols=[0, 1, 2])\n",
        "annos = pd.read_csv(csvfile[\"annos\"], header=0, index_col=0, usecols=[0, 1, 2])\n",
        "\n",
        "# print(frames.loc['bag', 'state'])\n",
        "# for fname, (url, state) in annos.iterrows():\n",
        "#     print(url, state)\n",
        "\n",
        "## V0.使用一个状态变量来记录是否已经下载成功\n",
        "def download_annos(use_proxy=True):\n",
        "    for fname, (url, state) in annos.iterrows():\n",
        "        folder_path = os.path.join(os.getcwd(), root, fname)\n",
        "\n",
        "        # 判断是否已经下载完成\n",
        "        if state:\n",
        "            print(f\"{fname} exists and have totaly been downloaded and unziped! Going to download and unzip the next.\")\n",
        "        else:\n",
        "            ## download\n",
        "            download_v1(url, folder_path, \"groundtruth\", use_proxy)\n",
        "            ## unzip\n",
        "            zip_src = folder_path + \"/groundtruth.zip\"\n",
        "            dest_dir = os.path.join(os.getcwd(), root, fname)\n",
        "            state = unzip_filev1(zip_src, dest_dir)\n",
        "            ## 将新的状态添加进入文件中\n",
        "            annos.loc[fname, \"state\"] = state\n",
        "            # print(annos.loc[fname][1])\n",
        "            annos.to_csv(csvfile[\"annos\"], index=fnames, encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def download_frames(use_proxy=True):\n",
        "    for fname, (url, state) in frames.iterrows():\n",
        "        folder_path = os.path.join(os.getcwd(), root, fname)\n",
        "\n",
        "        # 判断是否已经下载完成\n",
        "        if state:\n",
        "            print(f\"{fname} exists and have totaly been downloaded and unziped! Going to download and unzip the next.\")\n",
        "        else:\n",
        "            ## download\n",
        "            download_v1(url, folder_path, \"color\", use_proxy)\n",
        "            ## unzip\n",
        "            zip_src = folder_path + \"/color.zip\"\n",
        "            dest_dir = os.path.join(os.getcwd(), root, fname, \"color\")\n",
        "            state = unzip_filev0(zip_src, dest_dir)\n",
        "            frames.loc[fname, \"state\"] = state\n",
        "            frames.to_csv(csvfile[\"annos\"], index=fnames, encoding=\"utf-8\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "遇到的问题，成功解决参考链接：\n",
        "\n",
        "- https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas\n",
        "- https://jiaxiaochu.gitee.io/ibook/%E7%AC%AC2%E8%AF%BE/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E7%AC%AC%E4%BA%8C%E8%AF%BE.html\n",
        "- https://www.pythonf.cn/read/139075\n",
        "\n",
        "这里有第二种下载方案：就不用一个新的 `state` 来保存是否下载成功，而是直接使用 `os.path.exists(file)` 进行判断，因为只有成功下载并解压后，这文件才存在：`groundtruth.txt` 以及 `color/00000001.jpg`.\n",
        "\n",
        "这样更改的话会导致修改的地方有很多：\n",
        "\n",
        "1. `csv` 文件的写入格式要重新更改；\n",
        "2. `unzip` 部分需要修改，因为用不到了解压成功的状态；\n",
        "3. `download` 部分需要修改，包括使用 `pandas` 读取部分，以及下载代码块部分，删去状态标记以及重新写入 `csv` 文件的部分，然后更改判断条件即可。\n",
        "\n",
        "此次感悟：表层做判断，底层做细节处理，不要把判断放在后面（这里的后面不是说的最新添加的代码块，而是之前写的部分），原因是判断需要传值，越往里需要重复传入的参数次数越多，本来不是很复杂，但是经过这么一番操作之后，逻辑变得特别复杂，不容易看懂，降低了可读性。因此，应该尽量将逻辑处理部分放在最外层！！！\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "执行下载：如果在下载完成后自动解压，没有实现断点续传，只能将该值设置为 `False` !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ballet exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "bicycle exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "bike1 exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "bird1 exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "boat exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "bull exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "car1 exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "car3 exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "car6 exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "car8 exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "car9 exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "car16 exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "carchase exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "cat1 exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "cat2 exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "deer exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "dog exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "dragon exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "f1 exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "following exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "freesbiedog exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "freestyle exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "group1 exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "group2 exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "group3 exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "helicopter exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "horseride exists and have totaly been downloaded and unziped! Going to download and unzip the next.\n",
            "kitesurfing.zip downloaded: 0.00MB || Total size: 0.12MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "kitesurfing.zip: 100%|██████████| 121k/121k [00:00<00:00, 140kB/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip kitesurfing\n",
            "Done! KITESURFING has been unziped fully!\n",
            "liverRun.zip downloaded: 0.00MB || Total size: 0.72MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "liverRun.zip: 100%|██████████| 739k/739k [00:01<00:00, 503kB/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip liverRun\n",
            "Done! LIVERRUN has been unziped fully!\n",
            "longboard.zip downloaded: 0.00MB || Total size: 0.14MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "longboard.zip: 100%|██████████| 148k/148k [00:00<00:00, 193kB/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip longboard\n",
            "Done! LONGBOARD has been unziped fully!\n",
            "nissan.zip downloaded: 0.00MB || Total size: 0.09MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nissan.zip: 100%|██████████| 95.0k/95.0k [00:00<00:00, 125kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip nissan\n",
            "Done! NISSAN has been unziped fully!\n",
            "parachute.zip downloaded: 0.00MB || Total size: 0.07MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "parachute.zip: 100%|██████████| 73.8k/73.8k [00:00<00:00, 129kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip parachute\n",
            "Done! PARACHUTE has been unziped fully!\n",
            "person2.zip downloaded: 0.00MB || Total size: 0.06MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "person2.zip: 100%|██████████| 57.6k/57.6k [00:00<00:00, 114kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip person2\n",
            "Done! PERSON2 has been unziped fully!\n",
            "person4.zip downloaded: 0.00MB || Total size: 0.06MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "person4.zip: 100%|██████████| 59.5k/59.5k [00:00<00:00, 106kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip person4\n",
            "Done! PERSON4 has been unziped fully!\n",
            "person5.zip downloaded: 0.00MB || Total size: 0.05MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "person5.zip: 100%|██████████| 47.0k/47.0k [00:00<00:00, 93.8kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip person5\n",
            "Done! PERSON5 has been unziped fully!\n",
            "person7.zip downloaded: 0.00MB || Total size: 0.04MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "person7.zip: 100%|██████████| 44.9k/44.9k [00:00<00:00, 83.3kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip person7\n",
            "Done! PERSON7 has been unziped fully!\n",
            "person14.zip downloaded: 0.00MB || Total size: 0.06MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "person14.zip: 100%|██████████| 62.7k/62.7k [00:00<00:00, 121kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip person14\n",
            "Done! PERSON14 has been unziped fully!\n",
            "person17.zip downloaded: 0.00MB || Total size: 0.05MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "person17.zip: 100%|██████████| 50.3k/50.3k [00:00<00:00, 105kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip person17\n",
            "Done! PERSON17 has been unziped fully!\n",
            "person19.zip downloaded: 0.00MB || Total size: 0.09MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "person19.zip: 100%|██████████| 93.3k/93.3k [00:00<00:00, 157kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip person19\n",
            "Done! PERSON19 has been unziped fully!\n",
            "person20.zip downloaded: 0.00MB || Total size: 0.04MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "person20.zip: 100%|██████████| 41.2k/41.2k [00:00<00:00, 81.2kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip person20\n",
            "Done! PERSON20 has been unziped fully!\n",
            "rollerman.zip downloaded: 0.00MB || Total size: 0.03MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "rollerman.zip: 100%|██████████| 35.8k/35.8k [00:00<00:00, 153kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip rollerman\n",
            "Done! ROLLERMAN has been unziped fully!\n",
            "sitcom.zip downloaded: 0.00MB || Total size: 0.08MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "sitcom.zip: 100%|██████████| 81.4k/81.4k [00:00<00:00, 142kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip sitcom\n",
            "Done! SITCOM has been unziped fully!\n",
            "skiing.zip downloaded: 0.00MB || Total size: 0.06MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "skiing.zip: 100%|██████████| 57.1k/57.1k [00:00<00:00, 108kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip skiing\n",
            "Done! SKIING has been unziped fully!\n",
            "sup.zip downloaded: 0.00MB || Total size: 0.08MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "sup.zip: 100%|██████████| 86.1k/86.1k [00:00<00:00, 162kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip sup\n",
            "Done! SUP has been unziped fully!\n",
            "tightrope.zip downloaded: 0.00MB || Total size: 0.06MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tightrope.zip: 100%|██████████| 56.8k/56.8k [00:00<00:00, 107kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip tightrope\n",
            "Done! TIGHTROPE has been unziped fully!\n",
            "uav1.zip downloaded: 0.00MB || Total size: 0.07MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "uav1.zip: 100%|██████████| 72.4k/72.4k [00:00<00:00, 146kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip uav1\n",
            "Done! UAV1 has been unziped fully!\n",
            "volkswagen.zip downloaded: 0.00MB || Total size: 0.18MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "volkswagen.zip: 100%|██████████| 183k/183k [00:00<00:00, 213kB/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip volkswagen\n",
            "Done! VOLKSWAGEN has been unziped fully!\n",
            "warmup.zip downloaded: 0.00MB || Total size: 0.10MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "warmup.zip: 100%|██████████| 103k/103k [00:00<00:00, 137kB/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip warmup\n",
            "Done! WARMUP has been unziped fully!\n",
            "wingsuit.zip downloaded: 0.00MB || Total size: 0.06MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wingsuit.zip: 100%|██████████| 58.1k/58.1k [00:00<00:00, 109kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip wingsuit\n",
            "Done! WINGSUIT has been unziped fully!\n",
            "yamaha.zip downloaded: 0.00MB || Total size: 0.07MB || Remaining download rate 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "yamaha.zip: 100%|██████████| 72.7k/72.7k [00:00<00:00, 130kB/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start unzip yamaha\n",
            "Done! YAMAHA has been unziped fully!\n",
            "Done, groundtruth has been downloaded!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 下载 groundtruth.txt\n",
        "download_annos(use_proxy=True)\n",
        "print(\"Done, groundtruth has been downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 用于清楚下载的状态，重置为 False\n",
        "run_writer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "download_frames(use_proxy=True)  # 这里注释是为了方便之后演示，里面的文件太大\n",
        "print(\"Done, color.zip downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 解压文件\n",
        "# !./traverse.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "安装 `tree` 工具：`sudo apt-get install tree -y` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 查看当前目录结构\n",
        "!tree ./VOT2022_LT -L 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "可以看到有 `100` 个文件（50 个 `zip`，50 个 `.txt`）\n",
        "\n",
        "在执行以下命令删除压缩包之前，最好先保存一份，毕竟压缩包还是挺大的，防止意外发生。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 删除当前目录中所有的 .zip 文件！！！这里需要谨慎操作\n",
        "# !find -name \"groundtruth.zip\" | xargs rm -r\n",
        "# !find -name \"color.zip\" | xargs rm -r\n",
        "\n",
        "# 也可以一次删除\n",
        "# !find -name \"*.zip\" | xargs rm -r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Python` 爬虫教程：http://c.biancheng.net/view/2011.html\n",
        "\n",
        "`Python` 文件读写：\n",
        "  - http://www.itheima.com/news/20210412/113009.html\n",
        "  - https://www.cnblogs.com/zdz8207/p/python-updateFile-re-sub.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`VOT2022-LT`: https://data.votchallenge.net/vot2022/lt/description.json\n",
        "\n",
        "`sequence` 文件：\n",
        "```\n",
        "channels.color=color/%08d.jpg\n",
        "format=default\n",
        "fps=30\n",
        "name=agility\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "root = r\"./VOT2022_LT/sequences\"\n",
        "sequence = [\"channels.color=color/%08d.jpg\\r\\n\", \"format=default\\r\\n\", \"fps=30\\r\\n\"]\n",
        "\n",
        "# 测试代码\n",
        "# fsequence = \"./test.txt\"\n",
        "# fsequence = open(fsequence, encoding=\"utf-8\", mode=\"w\")\n",
        "# fsequence.writelines(sequence)\n",
        "# fsequence.flush()\n",
        "# fsequence.close()\n",
        "\n",
        "## 添加 list.txt 文件\n",
        "def write2list():\n",
        "    if not os.path.exists(root):\n",
        "        os.makedirs(root)\n",
        "    flist = os.path.join(root, \"list.txt\")\n",
        "\n",
        "    with open(flist, \"w\") as fl:\n",
        "        fl.writelines([fname + \"\\n\" for fname in fnames])\n",
        "\n",
        "\n",
        "def write2squence():\n",
        "    for fname in fnames:\n",
        "        ## 添加 sequence 文件\n",
        "        fsequence = os.path.join(root, fname, \"sequence\")\n",
        "        # print(fsequence)\n",
        "        if not os.path.exists(fsequence):\n",
        "            fsequence = open(fsequence, encoding=\"utf-8\", mode=\"w\")\n",
        "            fsequence.writelines(sequence)\n",
        "            fsequence.writelines(f\"name={fname}\\r\\n\")\n",
        "            fsequence.flush()\n",
        "            fsequence.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "write2list()\n",
        "write2squence()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!tree -L 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 补充：有关多进程下载以及下载进度条显示"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 一、下载进度条显示"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Python tqdm 工具包使用\n",
        "\n",
        "> 官网：https://pypi.org/project/tqdm/#examples-and-advanced-usage\n",
        "\n",
        "> 有关 `tqdm` 用法参考链接：https://pypi.org/project/tqdm/#examples-and-advanced-usage\n",
        "\n",
        "\n",
        "```python\n",
        "import urllib, os\n",
        "from tqdm import tqdm\n",
        "\n",
        "eg_link = \"https://caspersci.uk.to/matryoshka.zip\"\n",
        "response = getattr(urllib, 'request', urllib).urlopen(eg_link)\n",
        "with tqdm.wrapattr(open(os.devnull, \"wb\"), \"write\",\n",
        "                   miniters=1, desc=eg_link.split('/')[-1],\n",
        "                   total=getattr(response, 'length', None)) as fout:\n",
        "    for chunk in response:\n",
        "        fout.write(chunk)\n",
        "```\n",
        "\n",
        "还可以使用：\n",
        "```python\n",
        "import requests, os\n",
        "from tqdm import tqdm\n",
        "\n",
        "eg_link = \"https://caspersci.uk.to/matryoshka.zip\"\n",
        "response = requests.get(eg_link, stream=True)\n",
        "with tqdm.wrapattr(open(os.devnull, \"wb\"), \"write\",\n",
        "                   miniters=1, desc=eg_link.split('/')[-1],\n",
        "                   total=int(response.headers.get('content-length', 0))) as fout:\n",
        "    for chunk in response.iter_content(chunk_size=4096):\n",
        "        fout.write(chunk)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 二、Python 多进程下载"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 三、使用 `MD5` 进行文件完整性校验\n",
        "\n",
        "`MD5` 是一种数据加密手段，但可以通过该值进行完整性校验。\n",
        "\n",
        "> 参考链接：https://blog.csdn.net/python_neophyte/article/details/102645477\n",
        "\n",
        "```python\n",
        "import hashlib\n",
        "import os\n",
        "\n",
        "\n",
        "f_path = input('File path: ')\n",
        "SETUP_FILE = [file for file in os.listdir(f_path) if os.path.splitext(file)[1] == '.bin' or\n",
        "              (os.path.splitext(file)[1] == '.exe' and '%' not in os.path.splitext(file)[0])]\n",
        "MD5_FILE = [file for file in os.listdir(f_path) if os.path.splitext(file)[1] == '.md5']\n",
        "\n",
        "print('所有安装文件：', SETUP_FILE)\n",
        "print('MD5储存文件：', MD5_FILE)\n",
        "\n",
        "\n",
        "def get_correct_md5():\n",
        "    all_md5 = []\n",
        "\n",
        "    for file in MD5_FILE:\n",
        "        with open(os.path.join(f_path, file)) as f:\n",
        "            data = f.readlines()\n",
        "        all_md5.extend(data)\n",
        "\n",
        "    return all_md5\n",
        "\n",
        "def get_file_md5(file):\n",
        "    full_file_path = os.path.join(f_path, file)\n",
        "    m = hashlib.md5()\n",
        "    file_size = '{:.2f}'.format(os.path.getsize(full_file_path) / (1024 ** 2))\n",
        "    print('正在验证文件名称：%s， 文件大小：%s Mb' % (file, file_size))\n",
        "    with open(full_file_path, 'rb') as f:\n",
        "        while True:\n",
        "            data = f.read(99999999)\n",
        "            print('验证速度：%.2f Mb/s' % (len(data) / (1024 ** 2)), end='\\r')\n",
        "            if not data:\n",
        "                break\n",
        "            m.update(data)\n",
        "    file_md5 = m.hexdigest().upper()\n",
        "\n",
        "    return file_md5\n",
        "\n",
        "\n",
        "def main():\n",
        "    all_md5 = get_correct_md5()\n",
        "    bad_file = 0\n",
        "    print('开始验证：')\n",
        "    for file in SETUP_FILE:\n",
        "        md5 = get_file_md5(file)\n",
        "        for m in all_md5:\n",
        "            if file in m:\n",
        "                m = m.split(' ')\n",
        "                if md5 == m[0]:\n",
        "                    print(file, '\\n验证通过！\\n')\n",
        "                    break\n",
        "                else:\n",
        "                    print(file, '\\n文件损坏！\\n')\n",
        "                    bad_file += 1\n",
        "                    break\n",
        "        else:\n",
        "            print('此文件没有找到对应的md5，因此跳过验证。')\n",
        "\n",
        "    print('所有文件验证完成！')\n",
        "\n",
        "    if bad_file != 0:\n",
        "        print('共有 %s 个文件损坏，请重新下载损坏文件！' % bad_file)\n",
        "    else:\n",
        "        print('所有文件全部通过验证，可以直接安装！')\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "main()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `Git` 使用教程\n",
        "\n",
        "- VSCode上传本地项目到github https://www.cxyzjd.com/article/Le___Le/103585617\n",
        "- https://blog.csdn.net/qq_32578989/article/details/87994300\n",
        "\n",
        "### Step1: 在 GitHub 创建一个新的仓库，用于存储要提交的项目\n",
        "```bash\n",
        "cd workspace\n",
        "```\n",
        "\n",
        "### Step2: 与 GitHub 远程仓库建立联系\n",
        "```bash\n",
        "git init\n",
        "git remote rm origin\n",
        "git remote add origin https://github.com/blainetse/dataset_toolkits.git [ssh/https地址（要保存在 GitHub 的仓库位置）]\n",
        "git remote -v  # 查看状态\n",
        "```\n",
        "\n",
        "### Step3: push 到主分支\n",
        "```bash\n",
        "git pull origin master\n",
        "```\n",
        "\n",
        "注意：如果项目里已经有东西了，就可能会出现什么远程仓库和本地仓库不相关的错误，所以要\n",
        "```shell\n",
        "git pull origin master --allow-unrelated-histories\n",
        "```\n",
        "将 README等已有的文件强行拉下来！\n",
        "\n",
        "```bash\n",
        "git commit -m 注释内容——说明提交的状态等信息，字符串格式\n",
        "```\n",
        "\n",
        "如果有什么 nothing added to commit but untracked files present 的事，就直接 git add xxx.txt 或者 git add xxx/ 或者直接 git add -A 加所有，再 commit \n",
        "\n",
        "然后再 push 上去，git push -u origin master"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `Git` 配置问题记录\n",
        "\n",
        "`ERROR: Repository not found. Fatal: Could not read from remote repository.`\n",
        "  - https://blog.csdn.net/weixin_40886892/article/details/80725071"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "126376e67ac31299ba7cb89dcee7fcce5154bdeb432d12aa169075a6fbbc0094"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('d2l')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
