{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "参考链接：https://zhuanlan.zhihu.com/p/369531344\n",
        "\n",
        "文件操作：https://blog.csdn.net/Baozijiaruqing/article/details/103900387"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "关于 `VOT` 数据集下载，直接看官方源码：https://github.com/votchallenge/toolkit\n",
        "\n",
        "下载链接：https://data.votchallenge.net/vot2019/longterm/description.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: requests in /home/guest/anaconda3/envs/d2l/lib/python3.8/site-packages (2.27.1)\n",
            "Requirement already satisfied: pandas in /home/guest/anaconda3/envs/d2l/lib/python3.8/site-packages (1.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/guest/anaconda3/envs/d2l/lib/python3.8/site-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/guest/anaconda3/envs/d2l/lib/python3.8/site-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/guest/anaconda3/envs/d2l/lib/python3.8/site-packages (from requests) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/guest/anaconda3/envs/d2l/lib/python3.8/site-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/guest/anaconda3/envs/d2l/lib/python3.8/site-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /home/guest/anaconda3/envs/d2l/lib/python3.8/site-packages (from pandas) (1.20.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /home/guest/anaconda3/envs/d2l/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/guest/anaconda3/envs/d2l/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: urllib3<1.25 in /home/guest/anaconda3/envs/d2l/lib/python3.8/site-packages (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "# !pip install requests pandas\n",
        "# !pip install -U \"urllib3<1.25\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from urllib.parse import urlparse, urljoin\n",
        "\n",
        "VOT_DATASETS = {\n",
        "    \"vot2013\": \"http://data.votchallenge.net/vot2013/dataset/description.json\",\n",
        "    \"vot2014\": \"http://data.votchallenge.net/vot2014/dataset/description.json\",\n",
        "    \"vot2015\": \"http://data.votchallenge.net/vot2015/dataset/description.json\",\n",
        "    \"vot-tir2015\": \"http://www.cvl.isy.liu.se/research/datasets/ltir/version1.0/ltir_v1_0_8bit.zip\",\n",
        "    \"vot2016\": \"http://data.votchallenge.net/vot2016/main/description.json\",\n",
        "    \"vot-tir2016\": \"http://data.votchallenge.net/vot2016/vot-tir2016.zip\",\n",
        "    \"vot2017\": \"http://data.votchallenge.net/vot2017/main/description.json\",\n",
        "    \"vot-st2018\": \"http://data.votchallenge.net/vot2018/main/description.json\",\n",
        "    \"vot-lt2018\": \"http://data.votchallenge.net/vot2018/longterm/description.json\",\n",
        "    \"vot-st2019\": \"http://data.votchallenge.net/vot2019/main/description.json\",\n",
        "    \"vot-lt2019\": \"http://data.votchallenge.net/vot2019/longterm/description.json\",\n",
        "    \"vot-rgbd2019\": \"http://data.votchallenge.net/vot2019/rgbd/description.json\",\n",
        "    \"vot-rgbt2019\": \"http://data.votchallenge.net/vot2019/rgbtir/meta/description.json\",\n",
        "    \"vot-st2020\": \"https://data.votchallenge.net/vot2020/shortterm/description.json\",\n",
        "    \"vot-rgbt2020\": \"http://data.votchallenge.net/vot2020/rgbtir/meta/description.json\",\n",
        "    \"vot-st2021\": \"https://data.votchallenge.net/vot2021/shortterm/description.json\",\n",
        "    \"vot-lt2022\": \"https://data.votchallenge.net/vot2022/lt/description.json\",\n",
        "    \"test\": \"http://data.votchallenge.net/toolkit/test.zip\",\n",
        "    \"segmentation\": \"http://box.vicos.si/tracking/vot20_test_dataset.zip\",\n",
        "}\n",
        "stack = \"vot-lt2022\"\n",
        "url = VOT_DATASETS[stack]\n",
        "base_url = url.rsplit(\"/\", 1)[0] + \"/\"\n",
        "try:\n",
        "    meta = requests.get(url).json()\n",
        "except requests.exceptions.RequestException as e:\n",
        "    raise Exception(\"Unable to read JSON file {}\".format(e))\n",
        "\n",
        "color_url = []\n",
        "groundtruth_url = []\n",
        "fnames = []\n",
        "for sequence in meta[\"sequences\"]:\n",
        "    # get data name\n",
        "    fnames.append(sequence[\"name\"])\n",
        "\n",
        "    # get groundtruth zip file\n",
        "    url = sequence[\"annotations\"][\"url\"]\n",
        "    if bool(urlparse(url).netloc):\n",
        "        gt_url = url\n",
        "    else:\n",
        "        gt_url = urljoin(base_url, url)\n",
        "\n",
        "    # get pic zip file\n",
        "    url = sequence[\"channels\"][\"color\"][\"url\"]\n",
        "    if bool(urlparse(url).netloc):\n",
        "        pic_url = url\n",
        "    else:\n",
        "        pic_url = urljoin(base_url, url)\n",
        "\n",
        "    color_url.append(pic_url)\n",
        "    groundtruth_url.append(gt_url)\n",
        "\n",
        "for fname, link in zip(fnames, color_url):\n",
        "    print(f\"{fname}: {link}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 将数据写入 csv 文件\n",
        "import csv\n",
        "import os\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# 方法一：使用 csv 自带的接口，适合每行长度不一定全相等的情况\n",
        "def write2csv1(csvfile, fnames, urls):\n",
        "    if os.path.exists(csvfile):\n",
        "        print(f\"deleting {csvfile}...\")\n",
        "        os.remove(csvfile)\n",
        "\n",
        "    with open(csvfile, \"a+\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        # 1.写入 columns names\n",
        "        writer.writerow([\"文件名\", \"下载链接\"])\n",
        "        \n",
        "        for fname, url in zip(fnames, urls):\n",
        "            # 2.一行一行写入文件\n",
        "            # print(f\"正在将{fname}: {url} 写入到{csvfile}...\\n\")\n",
        "            writer.writerow([fname, url])\n",
        "\n",
        "# 方法二：使用 pandas\n",
        "def write2csv2(csvfile, fnames, urls):\n",
        "    if os.path.exists(csvfile):\n",
        "        print(f\"deleting {csvfile}...\")\n",
        "        os.remove(csvfile)\n",
        "    \n",
        "    # 1.创建一个 DataFrame 作为一行写入，以键值对——字典的形式存储\n",
        "    df = pd.DataFrame({\"文件名\": fnames, \"下载链接\": urls})\n",
        "    # 2.将 DataFrame 存储为 csv 文件，index 表示是否显示行名称（可以是数字，也可以是自定义的字符串）default=True\n",
        "    df.to_csv(csvfile, index=False, sep=\",\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = re.sub(\"[^0-9]\", \"\", stack)\n",
        "csvfile = {\n",
        "    \"color\": \"votlt\" + version + \"_color.csv\",\n",
        "    \"gt\": \"votlt\" + version + \"_gt.csv\",\n",
        "}\n",
        "\n",
        "\n",
        "def run_writer():\n",
        "    write2csv1(csvfile[\"color\"], fnames, color_url)\n",
        "    write2csv1(csvfile[\"gt\"], fnames, groundtruth_url)\n",
        "\n",
        "\n",
        "run_writer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import requests, os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 屏蔽warning信息\n",
        "requests.packages.urllib3.disable_warnings()\n",
        "# 构建自己的代理 IP 池\n",
        "proxies = {\n",
        "    \"http\": \"http://127.0.0.1:7890\",\n",
        "    \"https\": \"http://127.0.0.1:7890\",\n",
        "}\n",
        "# response = requests.get(url, proxies=proxies)\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.75 Safari/537.36\",\n",
        "}\n",
        "\n",
        "## 初级版：最原始的下载方法\n",
        "def download_v0(url, folder_path, fname):\n",
        "    fname = os.path.join(folder_path, f\"{fname}.zip\")\n",
        "\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)  # 创建存放每一个图片集的单独文件夹\n",
        "\n",
        "    # if not os.path.exists(fname):\n",
        "    if not os.path.isfile(fname):\n",
        "        response = requests.get(url, stream=True, proxies=proxies, headers=headers)\n",
        "        with open(fname, \"wb\") as code:\n",
        "            for chunk in response.iter_content(chunk_size=1024 * 32):  # 边下载边存硬盘\n",
        "                if chunk:\n",
        "                    code.write(chunk)\n",
        "            time.sleep(0.1)\n",
        "    else:\n",
        "        print(f\"{fname.title()} exists and have totaly been downloaded!\")\n",
        "\n",
        "\n",
        "## 进阶版：使用 tqdm 显示下载进度\n",
        "def download_v1(url, folder_path, fname):\n",
        "    fname = os.path.join(folder_path, f\"{fname}.zip\")\n",
        "\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)  # 创建存放每一个图片集的单独文件夹\n",
        "\n",
        "    ############# 断点续传实现 ##################\n",
        "    # 第一次请求是为了得到文件总大小\n",
        "    response = requests.get(url, stream=True, verify=False, proxies=proxies)\n",
        "    total_size = int(response.headers[\"Content-Length\"])\n",
        "\n",
        "    # 文件是否已经存在\n",
        "    if os.path.isfile(fname):\n",
        "        temp_size = os.path.getsize(fname)  # 本地已经下载的文件大小\n",
        "        if temp_size >= total_size:\n",
        "            print(\n",
        "                # 注意双引号中不能包括双引号！！！只能使用外面双引号，内部单引号\n",
        "                f\"{fname.split('/')[-2] + '.zip'} exists and have totaly been downloaded!\"\n",
        "            )\n",
        "            return\n",
        "    else:\n",
        "        temp_size = 0\n",
        "\n",
        "    # 显示一下下载了多少\n",
        "    print(\n",
        "        f\"{fname.split('/')[-2] + '.zip'} downloaded: {temp_size/(1024*1024):.2f}MB || Total size: {total_size/(1024*1024):.2f}MB || Remaining download rate {1 - temp_size/total_size:.2f}\"\n",
        "    )\n",
        "    # 核心部分，这个是请求下载时，从本地文件已经下载过的后面下载\n",
        "    # headers = {'Range': 'bytes=%d-' % temp_size}\n",
        "    headers = {\n",
        "        \"Range\": f\"bytes={temp_size}-{total_size}\",\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.75 Safari/537.36\",\n",
        "    }\n",
        "    # 重新请求网址，加入新的请求头的\n",
        "    response = requests.get(\n",
        "        url, stream=True, verify=False, headers=headers, proxies=proxies\n",
        "    )\n",
        "    ############################################\n",
        "\n",
        "    with tqdm.wrapattr(\n",
        "        open(fname, \"ab\"),  # 以 ab 追加的形式写入！！！\n",
        "        \"write\",\n",
        "        miniters=1,\n",
        "        # desc=url.split(\"/\")[-1],\n",
        "        desc=fname.split(\"/\")[-2] + \".zip\",\n",
        "        total=int(response.headers.get(\"content-length\", 0)),\n",
        "    ) as fout:\n",
        "        for chunk in response.iter_content(chunk_size=4096):\n",
        "            if chunk:\n",
        "                temp_size += len(chunk)\n",
        "                fout.write(chunk)\n",
        "                fout.flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "断点续传参考链接：\n",
        "- https://blog.csdn.net/qq_35203425/article/details/80987880\n",
        "- https://blog.csdn.net/thewindkee/article/details/80189434\n",
        "- https://huyi-aliang.blog.csdn.net/article/details/120926552?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_paycolumn_v3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_paycolumn_v3&utm_relevant_index=2 这篇比较准确"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "root = \"./VOT2022_LT/sequences\"\n",
        "\n",
        "color_data = pd.read_csv(csvfile[\"color\"], header=0, usecols=[0, 1]).values.tolist()\n",
        "gt_data = pd.read_csv(csvfile[\"gt\"], header=0, usecols=[0, 1]).values.tolist()\n",
        "\n",
        "\n",
        "def download_color():\n",
        "    for item in color_data:\n",
        "        fname, url = item[0], item[1]\n",
        "        folder_path = os.path.join(root, fname)\n",
        "        download_v1(url, folder_path, \"color\")\n",
        "        print(\"Done!\")\n",
        "\n",
        "\n",
        "def download_gt():\n",
        "    for item in gt_data:\n",
        "        fname, url = item[0], item[1]\n",
        "        folder_path = os.path.join(root, fname)\n",
        "        download_v1(url, folder_path, \"groundtruth\")\n",
        "        print(\"Done!\")\n",
        "\n",
        "\n",
        "# download_gt()\n",
        "download_color()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !find -name \"*.zip\" | xargs rm -r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Python` 爬虫教程：http://c.biancheng.net/view/2011.html\n",
        "\n",
        "`Python` 文件读写：\n",
        "  - http://www.itheima.com/news/20210412/113009.html\n",
        "  - https://www.cnblogs.com/zdz8207/p/python-updateFile-re-sub.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`VOT2022-LT`: https://data.votchallenge.net/vot2022/lt/description.json\n",
        "\n",
        "`sequence` 文件：\n",
        "```\n",
        "channels.color=color/%08d.jpg\n",
        "format=default\n",
        "fps=30\n",
        "name=agility\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 读写 sequence 文件\n",
        "sequence = [\"channels.color=color/%08d.jpg\\r\\n\", \"format=default\\r\\n\", \"fps=30\\r\\n\"]\n",
        "\n",
        "# 测试代码\n",
        "# source_file = \"./test.txt\"\n",
        "# source_file = open(source_file, encoding=\"utf-8\", mode=\"w\")\n",
        "# source_file.writelines(sequence)\n",
        "# source_file.flush()\n",
        "# source_file.close()\n",
        "\n",
        "for fname in fnames:\n",
        "    source_file = os.path.join(root, fname, \"sequence\")\n",
        "    # print(source_file)\n",
        "    if not os.path.exists(source_file):\n",
        "        source_file = open(source_file, encoding=\"utf-8\", mode=\"w\")\n",
        "        source_file.writelines(sequence)\n",
        "        source_file.writelines(f\"name={fname}\\r\\n\")\n",
        "        source_file.flush()\n",
        "        source_file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!tree -L 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 补充：有关多进程下载以及下载进度条显示"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 一、下载进度条显示"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Python tqdm 工具包使用\n",
        "\n",
        "> 官网：https://pypi.org/project/tqdm/#examples-and-advanced-usage\n",
        "\n",
        "> 有关 `tqdm` 用法参考链接：https://pypi.org/project/tqdm/#examples-and-advanced-usage\n",
        "\n",
        "\n",
        "```python\n",
        "import urllib, os\n",
        "from tqdm import tqdm\n",
        "\n",
        "eg_link = \"https://caspersci.uk.to/matryoshka.zip\"\n",
        "response = getattr(urllib, 'request', urllib).urlopen(eg_link)\n",
        "with tqdm.wrapattr(open(os.devnull, \"wb\"), \"write\",\n",
        "                   miniters=1, desc=eg_link.split('/')[-1],\n",
        "                   total=getattr(response, 'length', None)) as fout:\n",
        "    for chunk in response:\n",
        "        fout.write(chunk)\n",
        "```\n",
        "\n",
        "还可以使用：\n",
        "```python\n",
        "import requests, os\n",
        "from tqdm import tqdm\n",
        "\n",
        "eg_link = \"https://caspersci.uk.to/matryoshka.zip\"\n",
        "response = requests.get(eg_link, stream=True)\n",
        "with tqdm.wrapattr(open(os.devnull, \"wb\"), \"write\",\n",
        "                   miniters=1, desc=eg_link.split('/')[-1],\n",
        "                   total=int(response.headers.get('content-length', 0))) as fout:\n",
        "    for chunk in response.iter_content(chunk_size=4096):\n",
        "        fout.write(chunk)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 二、Python 多进程下载"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 三、使用 `MD5` 进行文件完整性校验\n",
        "\n",
        "`MD5` 是一种数据加密手段，但可以通过该值进行完整性校验。\n",
        "\n",
        "> 参考链接：https://blog.csdn.net/python_neophyte/article/details/102645477\n",
        "\n",
        "```python\n",
        "import hashlib\n",
        "import os\n",
        "\n",
        "\n",
        "f_path = input('File path: ')\n",
        "SETUP_FILE = [file for file in os.listdir(f_path) if os.path.splitext(file)[1] == '.bin' or\n",
        "              (os.path.splitext(file)[1] == '.exe' and '%' not in os.path.splitext(file)[0])]\n",
        "MD5_FILE = [file for file in os.listdir(f_path) if os.path.splitext(file)[1] == '.md5']\n",
        "\n",
        "print('所有安装文件：', SETUP_FILE)\n",
        "print('MD5储存文件：', MD5_FILE)\n",
        "\n",
        "\n",
        "def get_correct_md5():\n",
        "    all_md5 = []\n",
        "\n",
        "    for file in MD5_FILE:\n",
        "        with open(os.path.join(f_path, file)) as f:\n",
        "            data = f.readlines()\n",
        "        all_md5.extend(data)\n",
        "\n",
        "    return all_md5\n",
        "\n",
        "def get_file_md5(file):\n",
        "    full_file_path = os.path.join(f_path, file)\n",
        "    m = hashlib.md5()\n",
        "    file_size = '{:.2f}'.format(os.path.getsize(full_file_path) / (1024 ** 2))\n",
        "    print('正在验证文件名称：%s， 文件大小：%s Mb' % (file, file_size))\n",
        "    with open(full_file_path, 'rb') as f:\n",
        "        while True:\n",
        "            data = f.read(99999999)\n",
        "            print('验证速度：%.2f Mb/s' % (len(data) / (1024 ** 2)), end='\\r')\n",
        "            if not data:\n",
        "                break\n",
        "            m.update(data)\n",
        "    file_md5 = m.hexdigest().upper()\n",
        "\n",
        "    return file_md5\n",
        "\n",
        "\n",
        "def main():\n",
        "    all_md5 = get_correct_md5()\n",
        "    bad_file = 0\n",
        "    print('开始验证：')\n",
        "    for file in SETUP_FILE:\n",
        "        md5 = get_file_md5(file)\n",
        "        for m in all_md5:\n",
        "            if file in m:\n",
        "                m = m.split(' ')\n",
        "                if md5 == m[0]:\n",
        "                    print(file, '\\n验证通过！\\n')\n",
        "                    break\n",
        "                else:\n",
        "                    print(file, '\\n文件损坏！\\n')\n",
        "                    bad_file += 1\n",
        "                    break\n",
        "        else:\n",
        "            print('此文件没有找到对应的md5，因此跳过验证。')\n",
        "\n",
        "    print('所有文件验证完成！')\n",
        "\n",
        "    if bad_file != 0:\n",
        "        print('共有 %s 个文件损坏，请重新下载损坏文件！' % bad_file)\n",
        "    else:\n",
        "        print('所有文件全部通过验证，可以直接安装！')\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "main()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `Git` 使用教程\n",
        "\n",
        "- VSCode上传本地项目到github https://www.cxyzjd.com/article/Le___Le/103585617\n",
        "- https://blog.csdn.net/qq_32578989/article/details/87994300\n",
        "\n",
        "### Step1: 在 GitHub 创建一个新的仓库，用于存储要提交的项目\n",
        "```bash\n",
        "cd workspace\n",
        "```\n",
        "\n",
        "### Step2: 与 GitHub 远程仓库建立联系\n",
        "```bash\n",
        "git init\n",
        "git remote rm origin\n",
        "git remote add origin https://github.com/blainetse/dataset_toolkits.git [ssh/https地址（要保存在 GitHub 的仓库位置）]\n",
        "git remote -v  # 查看状态\n",
        "```\n",
        "\n",
        "### Step3: push 到主分支\n",
        "```bash\n",
        "git pull origin master\n",
        "```\n",
        "\n",
        "注意：如果项目里已经有东西了，就可能会出现什么远程仓库和本地仓库不相关的错误，所以要\n",
        "```shell\n",
        "git pull origin master --allow-unrelated-histories\n",
        "```\n",
        "将 README等已有的文件强行拉下来！\n",
        "\n",
        "```bash\n",
        "git commit -m 注释内容——说明提交的状态等信息，字符串格式\n",
        "```\n",
        "\n",
        "如果有什么 nothing added to commit but untracked files present 的事，就直接 git add xxx.txt 或者 git add xxx/ 或者直接 git add -A 加所有，再 commit \n",
        "\n",
        "然后再 push 上去，git push -u origin master"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `Git` 配置问题记录\n",
        "\n",
        "`ERROR: Repository not found. Fatal: Could not read from remote repository.`\n",
        "  - https://blog.csdn.net/weixin_40886892/article/details/80725071"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "126376e67ac31299ba7cb89dcee7fcce5154bdeb432d12aa169075a6fbbc0094"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('d2l')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
